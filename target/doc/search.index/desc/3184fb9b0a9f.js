rd_("AoReturns the argument unchanged.0000BaCalls <code>U::from(self)</code>.0000ChParse given key text. Does not copy the text, so the \xe2\x80\xa6CkParse body of this Parser\xe2\x80\x99s robots.txt and emit parse \xe2\x80\xa6A`A parser module.CgUnrecognized field; kept as-is. High number so that \xe2\x80\xa6AaA matcher module.CkReturns true if URI path matches the specified pattern. \xe2\x80\xa6AhReturns the type of key.CjA native Rust port of Google\xe2\x80\x99s robots.txt parser and \xe2\x80\xa6BiA enum represents key types in robotstxt.C`RobotsMatcher - matches robots.txt against URLs.B`A default RobotsMatcher with \xe2\x80\xa6CbCanonicalize the allowed/disallowed path patterns.C`A robots.txt has lines of key/value pairs. A \xe2\x80\xa6AcA robotstxt parser.CkAttempts to parse a line of robots.txt into a key/value \xe2\x80\xa6CjParses body of a robots.txt and emits parse callbacks. \xe2\x80\xa6BhIf this is an unknown key, get the text.CmReturns true if \xe2\x80\x98url\xe2\x80\x99 is allowed to be fetched by any \xe2\x80\xa6BkHandler for directives found in robots.txt.CjCreate a RobotsMatcher with the default matching strategy.ChExtracts path (with params) and query part from URL. \xe2\x80\xa6BhAny other unrecognized name/value pairs.CmVerifies that the given user agent is valid to be matched \xe2\x80\xa6CmDo robots check for \xe2\x80\x98url\xe2\x80\x99 when there is only one user \xe2\x80\xa6ClImplements the default robots.txt matching strategy. The \xe2\x80\xa6")